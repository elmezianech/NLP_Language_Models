{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2124baec-d62e-4bd8-b2bd-7aa8495491b3",
   "metadata": {},
   "source": [
    "# Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa20767-a7fa-4882-a0d1-bde0589e6200",
   "metadata": {},
   "source": [
    "##### Objective : The main purpose behind this lab is to get familiar with NLP language models using Pytorch library.\r",
    "\r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09e5a3-8380-4399-bbe7-0fb70465bf49",
   "metadata": {},
   "source": [
    "## Part 1 : Classification Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6fdfe9-d0b1-4ed2-9c51-e78b92fce304",
   "metadata": {},
   "source": [
    "### Step 1 : Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23b48236-4f49-4307-a03e-92a121ef848a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 13:39:18 [scrapy.utils.log] INFO: Scrapy 2.11.1 started (bot: scrapybot)\n",
      "2024-05-26 13:39:18 [scrapy.utils.log] INFO: Versions: lxml 5.1.0.0, libxml2 2.10.3, cssselect 1.2.0, parsel 1.9.0, w3lib 2.1.2, Twisted 24.3.0, Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 24.0.0 (OpenSSL 3.2.1 30 Jan 2024), cryptography 42.0.5, Platform Windows-10-10.0.19045-SP0\n",
      "2024-05-26 13:39:18 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2024-05-26 13:39:18 [py.warnings] WARNING: C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scrapy\\utils\\request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2024-05-26 13:39:18 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2024-05-26 13:39:18 [scrapy.extensions.telnet] INFO: Telnet Password: 491e2360483149a1\n",
      "2024-05-26 13:39:19 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2024-05-26 13:39:19 [scrapy.crawler] INFO: Overridden settings:\n",
      "{}\n",
      "2024-05-26 13:39:19 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2024-05-26 13:39:19 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2024-05-26 13:39:19 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2024-05-26 13:39:19 [scrapy.core.engine] INFO: Spider opened\n",
      "2024-05-26 13:39:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2024-05-26 13:39:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2024-05-26 13:39:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://arabpoems.com/%D8%AD%D9%83%D9%85-%D9%88%D8%A3%D9%85%D8%AB%D8%A7%D9%84/> (referer: None)\n",
      "2024-05-26 13:39:21 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2024-05-26 13:39:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 270,\n",
      " 'downloader/request_count': 1,\n",
      " 'downloader/request_method_count/GET': 1,\n",
      " 'downloader/response_bytes': 28126,\n",
      " 'downloader/response_count': 1,\n",
      " 'downloader/response_status_count/200': 1,\n",
      " 'elapsed_time_seconds': 1.397861,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2024, 5, 26, 12, 39, 21, 18621, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 172863,\n",
      " 'httpcompression/response_count': 1,\n",
      " 'log_count/DEBUG': 2,\n",
      " 'log_count/INFO': 10,\n",
      " 'log_count/WARNING': 1,\n",
      " 'response_received_count': 1,\n",
      " 'scheduler/dequeued': 1,\n",
      " 'scheduler/dequeued/memory': 1,\n",
      " 'scheduler/enqueued': 1,\n",
      " 'scheduler/enqueued/memory': 1,\n",
      " 'start_time': datetime.datetime(2024, 5, 26, 12, 39, 19, 620760, tzinfo=datetime.timezone.utc)}\n",
      "2024-05-26 13:39:21 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import random\n",
    "import json\n",
    "\n",
    "class ArabicProverbsSpider(scrapy.Spider):\n",
    "    name = \"arabic_proverbs\"\n",
    "    start_urls = ['https://arabpoems.com/حكم-وأمثال/']\n",
    "\n",
    "    def parse(self, response):\n",
    "        # Extracting the content of each <li> inside a <ul> inside a <div>\n",
    "        proverbs = response.css('div.entry-content ul li::text, div.entry-content ul li strong::text').getall()\n",
    "\n",
    "        # Clean and structure the data\n",
    "        data = []\n",
    "        for proverb in proverbs:\n",
    "            proverb_encoded = proverb.strip().encode('utf-8').decode('utf-8')\n",
    "            data.append({'Text': proverb_encoded, 'Score': round(random.uniform(0, 10), 1)})\n",
    "\n",
    "        # Save the data to a JSON file\n",
    "        with open('arabic_proverbs.json', 'w', encoding='utf-8') as jsonfile:\n",
    "            json.dump(data, jsonfile, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Run the Scrapy crawler\n",
    "process = CrawlerProcess()\n",
    "process.crawl(ArabicProverbsSpider)\n",
    "process.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "424a9830-cdf6-486e-a48f-0d281197534d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>أشفق عليك في شبابك حتى تجد من يشفق عليك وأنت ر...</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>من صاحب العلماء وقر- مثل لبناني.</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قال الإمام علي بن أبي طالب: ليس اليتيم من مات ...</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>النجاح لا يحتاج إلى أقدام بل إلى إقدام.</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>روى الأصمعي في احد مؤلفاته: أول العلم الصمت وا...</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  أشفق عليك في شبابك حتى تجد من يشفق عليك وأنت ر...    3.3\n",
       "1                   من صاحب العلماء وقر- مثل لبناني.    4.3\n",
       "2  قال الإمام علي بن أبي طالب: ليس اليتيم من مات ...    8.8\n",
       "3            النجاح لا يحتاج إلى أقدام بل إلى إقدام.    9.1\n",
       "4  روى الأصمعي في احد مؤلفاته: أول العلم الصمت وا...    2.3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Read the JSON file into a DataFrame\n",
    "df = pd.read_json('arabic_proverbs.json', encoding='utf-8')\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf23f3-ebf8-4fdd-bc0f-2c0d00bfe2ed",
   "metadata": {},
   "source": [
    "### Step 2 : Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af757121-e77d-46aa-9ab3-9ead209fc4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 22:08:27 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a99d993d784b2db97b3482a1faaa09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 22:08:33 INFO: Downloaded file to C:\\Users\\admin\\stanza_resources\\resources.json\n",
      "2024-05-26 22:08:33 WARNING: Language ar package default expects mwt, which has been added\n",
      "2024-05-26 22:08:33 INFO: Loading these models for language: ar (Arabic):\n",
      "=============================\n",
      "| Processor | Package       |\n",
      "-----------------------------\n",
      "| tokenize  | padt          |\n",
      "| mwt       | padt          |\n",
      "| lemma     | padt_nocharlm |\n",
      "=============================\n",
      "\n",
      "2024-05-26 22:08:33 INFO: Using device: cpu\n",
      "2024-05-26 22:08:33 INFO: Loading: tokenize\n",
      "2024-05-26 22:08:33 INFO: Loading: mwt\n",
      "2024-05-26 22:08:33 INFO: Loading: lemma\n",
      "2024-05-26 22:08:33 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import stanza\n",
    "\n",
    "\n",
    "# Download the Arabic models for the neural pipeline\n",
    "nlp = stanza.Pipeline('ar', processors='tokenize,lemma')\n",
    "\n",
    "# Remove Diacritization\n",
    "def remove_diacritics(text):\n",
    "    arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Shadda\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n",
    "    text = re.sub(arabic_diacritics, '', text)\n",
    "    return text\n",
    "\n",
    "# Text Cleaning and Preprocessing\n",
    "def clean_text(text):\n",
    "    # Remove extra whitespace and punctuation/special characters\n",
    "    pattern = r\"[^\\w\\s]\"  # Matches characters that are not alphanumeric or whitespace\n",
    "    text = re.sub(pattern, '', text)\n",
    "    # Remove stopwords\n",
    "    arabic_stopwords = stopwords.words(\"arabic\")\n",
    "    text = ' '.join(word for word in text.split() if word not in arabic_stopwords)\n",
    "    # Remove Diactitics\n",
    "    text = remove_diacritics(text)\n",
    "    # Normalize characters for consistent representation (especially for Arabic)\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    return text\n",
    "\n",
    "# Text Tokenization\n",
    "def tokenize_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# Lemmatization using Stanza Library\n",
    "def lemmatize_text(text):\n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "    # Lemmatize the tokens\n",
    "    lemmatized_tokens = [word.lemma for sent in doc.sentences for word in sent.words]\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6405d1b6-204c-4635-bff6-9988ec5bcb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>Clean_Text</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "      <th>Lemmatized_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>أشفق عليك في شبابك حتى تجد من يشفق عليك وأنت ر...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>أشفق شبابك تجد يشفق وأنت رجل كبير</td>\n",
       "      <td>[أشفق, شبابك, تجد, يشفق, وأنت, رجل, كبير]</td>\n",
       "      <td>[أشفق, شبابك, وَجَد, يشفق, وأنت, رَجُل, كَبِير]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>من صاحب العلماء وقر- مثل لبناني.</td>\n",
       "      <td>4.3</td>\n",
       "      <td>صاحب العلماء وقر لبناني</td>\n",
       "      <td>[صاحب, العلماء, وقر, لبناني]</td>\n",
       "      <td>[صَاحِب, عَالِم, وَقرَة, لُبنَانِيّ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>قال الإمام علي بن أبي طالب: ليس اليتيم من مات ...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>قال الإمام علي بن أبي طالب اليتيم مات والده ...</td>\n",
       "      <td>[قال, الإمام, علي, بن, أبي, طالب, اليتيم, ما...</td>\n",
       "      <td>[قَال, الإمام, عَلَى, بِن, أبي, طَالَب, اليت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>النجاح لا يحتاج إلى أقدام بل إلى إقدام.</td>\n",
       "      <td>9.1</td>\n",
       "      <td>النجاح يحتاج أقدام إقدام</td>\n",
       "      <td>[النجاح, يحتاج, أقدام, إقدام]</td>\n",
       "      <td>[نَجَاح, اِحتَاج, أقدام, إقدام]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>روى الأصمعي في احد مؤلفاته: أول العلم الصمت وا...</td>\n",
       "      <td>2.3</td>\n",
       "      <td>روى الأصمعي احد مؤلفاته العلم الصمت والثاني ...</td>\n",
       "      <td>[روى, الأصمعي, احد, مؤلفاته, العلم, الصمت, و...</td>\n",
       "      <td>[روى, الأصمعي, أَحَد, مو&lt;UNK&gt;لفات, هُوَ, عَلَ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score  \\\n",
       "0  أشفق عليك في شبابك حتى تجد من يشفق عليك وأنت ر...    3.3   \n",
       "1                   من صاحب العلماء وقر- مثل لبناني.    4.3   \n",
       "2  قال الإمام علي بن أبي طالب: ليس اليتيم من مات ...    8.8   \n",
       "3            النجاح لا يحتاج إلى أقدام بل إلى إقدام.    9.1   \n",
       "4  روى الأصمعي في احد مؤلفاته: أول العلم الصمت وا...    2.3   \n",
       "\n",
       "                                          Clean_Text  \\\n",
       "0                أشفق شبابك تجد يشفق وأنت رجل كبير   \n",
       "1                            صاحب العلماء وقر لبناني   \n",
       "2  قال الإمام علي بن أبي طالب اليتيم مات والده ...   \n",
       "3                         النجاح يحتاج أقدام إقدام   \n",
       "4  روى الأصمعي احد مؤلفاته العلم الصمت والثاني ...   \n",
       "\n",
       "                                      Tokenized_Text  \\\n",
       "0        [أشفق, شبابك, تجد, يشفق, وأنت, رجل, كبير]   \n",
       "1                       [صاحب, العلماء, وقر, لبناني]   \n",
       "2  [قال, الإمام, علي, بن, أبي, طالب, اليتيم, ما...   \n",
       "3                    [النجاح, يحتاج, أقدام, إقدام]   \n",
       "4  [روى, الأصمعي, احد, مؤلفاته, العلم, الصمت, و...   \n",
       "\n",
       "                                     Lemmatized_Text  \n",
       "0  [أشفق, شبابك, وَجَد, يشفق, وأنت, رَجُل, كَبِير]  \n",
       "1               [صَاحِب, عَالِم, وَقرَة, لُبنَانِيّ]  \n",
       "2  [قَال, الإمام, عَلَى, بِن, أبي, طَالَب, اليت...  \n",
       "3                  [نَجَاح, اِحتَاج, أقدام, إقدام]  \n",
       "4  [روى, الأصمعي, أَحَد, مو<UNK>لفات, هُوَ, عَلَ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the clean_text function\n",
    "df['Clean_Text'] = df['Text'].apply(clean_text)\n",
    "\n",
    "# Apply the tokenize_text function\n",
    "df['Tokenized_Text'] = df['Clean_Text'].apply(tokenize_text)\n",
    "\n",
    "# Apply the lemmatize_text function\n",
    "df['Lemmatized_Text'] = df['Clean_Text'].apply(lemmatize_text)\n",
    "\n",
    "# Display the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85fc8751-6ea2-4dad-a851-92c46006206e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Lemmatized_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.3</td>\n",
       "      <td>[أشفق, شبابك, وَجَد, يشفق, وأنت, رَجُل, كَبِير]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.3</td>\n",
       "      <td>[صَاحِب, عَالِم, وَقرَة, لُبنَانِيّ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.8</td>\n",
       "      <td>[قَال, الإمام, عَلَى, بِن, أبي, طَالَب, اليت...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.1</td>\n",
       "      <td>[نَجَاح, اِحتَاج, أقدام, إقدام]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.3</td>\n",
       "      <td>[روى, الأصمعي, أَحَد, مو&lt;UNK&gt;لفات, هُوَ, عَلَ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>4.8</td>\n",
       "      <td>[المتشائم, رَأَى, حَيَاة, ظُلُّه]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2.6</td>\n",
       "      <td>[إني, لِ, أ&lt;UNK&gt;عجب, يظن, حَيَاة, شِيِّيّ, وَ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>9.8</td>\n",
       "      <td>[حُرِّيَّة, حَيَاة, حُرِّيَّة, بِ, لَا, فَضِيلَة]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>4.4</td>\n",
       "      <td>[لَحِيايّ, قِيمَة, وَجدَنَا, شِيِّيّ, نناضل, ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>4.2</td>\n",
       "      <td>[حَيَاة, شعلة, نحترق, بِنَار, هُوَ, نطفي&lt;UNK&gt;,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Score                                    Lemmatized_Text\n",
       "0      3.3  [أشفق, شبابك, وَجَد, يشفق, وأنت, رَجُل, كَبِير]\n",
       "1      4.3               [صَاحِب, عَالِم, وَقرَة, لُبنَانِيّ]\n",
       "2      8.8  [قَال, الإمام, عَلَى, بِن, أبي, طَالَب, اليت...\n",
       "3      9.1                  [نَجَاح, اِحتَاج, أقدام, إقدام]\n",
       "4      2.3  [روى, الأصمعي, أَحَد, مو<UNK>لفات, هُوَ, عَلَ...\n",
       "..     ...                                                ...\n",
       "282    4.8                 [المتشائم, رَأَى, حَيَاة, ظُلُّه]\n",
       "283    2.6  [إني, لِ, أ<UNK>عجب, يظن, حَيَاة, شِيِّيّ, وَ...\n",
       "284    9.8  [حُرِّيَّة, حَيَاة, حُرِّيَّة, بِ, لَا, فَضِيلَة]\n",
       "285    4.4  [لَحِيايّ, قِيمَة, وَجدَنَا, شِيِّيّ, نناضل, ا...\n",
       "286    4.2  [حَيَاة, شعلة, نحترق, بِنَار, هُوَ, نطفي<UNK>,...\n",
       "\n",
       "[287 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "df.drop(columns=['Text', 'Clean_Text', 'Tokenized_Text'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daa9d9e-9116-4a1a-ad2c-512a95ffafe7",
   "metadata": {},
   "source": [
    "### Step 3 : Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dda53b0d-eb97-4151-ac63-f584016638e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.012013378801371877\n",
      "Mean Squared Error (MSE): 8.866586663374566\n",
      "Mean Absolute Error (MAE): 2.6641339737793497\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define your dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx]), torch.tensor(self.y[idx])\n",
    "\n",
    "# Define your RNN model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.rnn(embedded)\n",
    "        output = self.fc(output[:, -1, :])\n",
    "        return output\n",
    "\n",
    "# Define your hyperparameters\n",
    "input_size = 10000  # Vocabulary size\n",
    "hidden_size = 128\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Preprocessing\n",
    "X = df['Lemmatized_Text'].values\n",
    "y = df['Score'].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences\n",
    "max_length = max(len(seq) for seq in X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
    "\n",
    "max_length_test = max(len(seq) for seq in X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length_test, padding='post')\n",
    "\n",
    "# Create DataLoader for training and testing\n",
    "train_dataset = MyDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataset = MyDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = RNNModel(input_size, hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.flatten(), targets.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            y_true.extend(targets.numpy())\n",
    "            y_pred.extend(outputs.flatten().numpy())\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    return r2, mse, mae\n",
    "\n",
    "r2, mse, mae = evaluate_model(model, test_loader)\n",
    "print(\"R2 Score:\", r2)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec26954b-aee1-466e-ab86-e03d8c49e6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.03337051827001869\n",
      "Mean Squared Error (MSE): 8.674919161085116\n",
      "Mean Absolute Error (MAE): 2.640769938764901\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, _ = self.lstm(embedded)\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc(output[:, -1, :])\n",
    "        return output\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = LSTMModel(input_size, hidden_size, num_layers=2, dropout=0.5)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.flatten(), targets.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "r2, mse, mae = evaluate_model(model, test_loader)\n",
    "print(\"R2 Score:\", r2)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7d00ab3-9aee-4656-9ad2-47c2ca8bea1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -0.054461934300437775\n",
      "Mean Squared Error (MSE): 9.463162681658176\n",
      "Mean Absolute Error (MAE): 2.732141784141804\n"
     ]
    }
   ],
   "source": [
    "# Define your Bidirectional GRU model\n",
    "class BiGRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(BiGRUModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)  # Multiply by 2 for bidirection\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.gru(embedded)\n",
    "        output = self.fc(torch.cat((output[:, -1, :hidden_size], output[:, 0, hidden_size:]), dim=1))  # Concatenate the last hidden state from forward and backward pass\n",
    "        return output\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = BiGRUModel(input_size, hidden_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.flatten(), targets.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "r2, mse, mae = evaluate_model(model, test_loader)\n",
    "print(\"R2 Score:\", r2)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e93555-12f4-43da-88a0-22eed3d5f115",
   "metadata": {},
   "source": [
    "### Step 4 : Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd48e7b-f90a-4111-911e-82ce0a178b12",
   "metadata": {},
   "source": [
    "Analysis\n",
    "\r",
    "- **R2 Score** Measures how well the predictions approximate the actual values. Higher is better. The LSTM model performed slightly better than the RNN model, while the BiGRU model had a negative R2 score, indicating poor performance.\n",
    "- The **MSE** Measures the average squared difference between predictions and actual values. Lower is better. The LSTM model had the lowest MSE, indicating it was the most accurate in terms of average squared error.\n",
    "- **MAE** Measures the average absolute difference between predictions and actual values. Lower is better. The LSTM model also had the lowest MAE, making it the best at minimizing absolute error.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "- **Best Model** The LSTM model showed the best performance across most metrics (R2 Score, MSE, and MAE).\n",
    "iction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
